{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from util import convert_tokens, get_batch_dataset, get_dataset, get_record_parser\n",
    "import tensorflow as tf\n",
    "from config import flags\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_string('f', 'give up already', 'who cares lol')\n",
    "config = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_file = 'data/og_check_test_meta.json'\n",
    "test_record_file = 'data/og_check_test.tf'\n",
    "\n",
    "#test_eval_file = 'data/sample1k-HCVerifyAll_eval.json'\n",
    "#test_record_file = 'data/sample1k-HCVerifyAll.tfrecords'\n",
    "\n",
    "with open(test_eval_file, \"r\") as fh:\n",
    "    eval_file = json.load(fh)\n",
    "\n",
    "meta = {'total': 1382}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.word_emb_file, \"r\") as fh:\n",
    "    word_mat = np.array(json.load(fh), dtype=np.float32)\n",
    "with open(config.char_emb_file, \"r\") as fh:\n",
    "    char_mat = np.array(json.load(fh), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = get_dataset(test_record_file, get_record_parser(\n",
    "        config, is_test=True), config).make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/soham/NLU-Project/env/local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "model = Model(config, test_batch, word_mat, char_mat, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=sess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log/model/model_60000.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint(config.save_dir))\n",
    "sess.run(tf.assign(model.is_train, tf.constant(False, dtype=tf.bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382\n"
     ]
    }
   ],
   "source": [
    "total = meta['total']\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer_dict = {}\n",
    "remapped_dict = {}\n",
    "\n",
    "for step in range(total // config.batch_size + 1):\n",
    "    qa_id, loss, yp1, yp2 = sess.run([model.qa_id, model.loss, model.yp1, model.yp2])\n",
    "    answer_dict_, remapped_dict_ = convert_tokens(eval_file, qa_id.tolist(), yp1.tolist(), yp2.tolist())\n",
    "    answer_dict.update(answer_dict_)\n",
    "    remapped_dict.update(remapped_dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import metric_max_over_ground_truths, exact_match_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_file, answer_dict, only=None):\n",
    "    f1 = exact_match = total = 0\n",
    "    for key, value in answer_dict.items():\n",
    "        if only == 'adv' and len(eval_file[key]['uuid'].split('-')) == 1:\n",
    "            continue\n",
    "        if only == 'orig' and len(eval_file[key]['uuid'].split('-')) > 1:\n",
    "            continue\n",
    "        total += 1\n",
    "        ground_truths = eval_file[key][\"answers\"]\n",
    "        prediction = value\n",
    "        exact_match += metric_max_over_ground_truths(\n",
    "            exact_match_score, prediction, ground_truths)\n",
    "        f1 += metric_max_over_ground_truths(f1_score,\n",
    "                                            prediction, ground_truths)\n",
    "#         if metric_max_over_ground_truths(exact_match_score, prediction, ground_truths) < 1:\n",
    "#             print(eval_file[key]['uuid'])\n",
    "#             print(eval_file[key]['context'])\n",
    "#             print(eval_file[key]['answers'])\n",
    "#             print(eval_file[key]['question'])\n",
    "#             print(value)\n",
    "#             print()\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "    return {'exact_match': exact_match, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmutated data\n",
      "Exact Match: 66.58163265306122, F1: 76.31934495366053\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(eval_file, answer_dict, only='orig')\n",
    "print(\"Unmutated data\")\n",
    "print(\"Exact Match: {}, F1: {}\".format(metrics['exact_match'], metrics['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutated data\n",
      "Exact Match: 34.07482305358948, F1: 42.11778008855463\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(eval_file, answer_dict, only='adv')\n",
    "print(\"Mutated data\")\n",
    "print(\"Exact Match: {}, F1: {}\".format(metrics['exact_match'], metrics['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall\n",
      "Exact Match: 43.30195510499638, F1: 51.8259722877736\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(eval_file, answer_dict)\n",
    "print(\"Overall\")\n",
    "print(\"Exact Match: {}, F1: {}\".format(metrics['exact_match'], metrics['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = False\n",
    "\n",
    "for step in range(1400 // config.batch_size + 1):\n",
    "    qa_id, yp1_distrib, yp2_distrib, qc_att, c_len, q_len = sess.run([model.qa_id, tf.nn.softmax(model.yp1_distrib), tf.nn.softmax(model.yp2_distrib), model.qc_att, model.c_len, model.q_len])\n",
    "    \n",
    "    for kkk, _id_ in enumerate(qa_id):\n",
    "        if eval_file[str(_id_)]['uuid'] == '57280fd3ff5b5019007d9c26-mut0':\n",
    "            print('hi')\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if found:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = [str(x).encode('utf8', 'ignore').decode('unicode_escape') for x in nlp('''French Huguenot explorer Jean Ribault charted the St. Johns River in 1562 calling it the River of May because he discovered it in May. Ribault erected a stone column near present-day Jacksonville claiming the newly discovered land for France. Jeff Dean mapped the Saint Hopkins Creek in 1563. In 1564, René Goulaine de Laudonnière established the first European settlement, Fort Caroline, on the St. Johns near the main village of the Saturiwa. Philip II of Spain ordered Pedro Menéndez de Avilés to protect the interest of Spain by attacking the French presence at Fort Caroline. On September 20, 1565, a Spanish force from the nearby Spanish settlement of St. Augustine attacked Fort Caroline, and killed nearly all the French soldiers defending it. The Spanish renamed the fort San Mateo, and following the ejection of the French, St. Augustine's position as the most important settlement in Florida was solidified. The location of Fort Caroline is subject to debate but a reconstruction of the fort was established on the St. Johns River in 1964.''')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_ = [str(x).encode('utf8', 'ignore').decode('unicode_escape') for x in nlp('Who mapped the St. Johns River in 1562?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file[str(qa_id[kkk])]['uuid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_len[kkk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_len[kkk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(passage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(question_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(['%.4f' % kkkkkkk for kkkkkkk in yp1_distrib[kkk][:c_len[kkk]].round(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "for x, y in zip(passage, yp1_distrib[kkk][:c_len[kkk]]):\n",
    "    print(x,y)\n",
    "    total += y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp2_distrib[kkk][:c_len[kkk]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_att[kkk][:c_len[kkk],:q_len[kkk]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[')\n",
    "for i in range(c_len[kkk]):\n",
    "    print(json.dumps(['%.4f' % kkkkkkk for kkkkkkk in qc_att[kkk][i,:q_len[kkk]].round(4)]), ',')\n",
    "print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yp2[kkk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, vec in enumerate(c_emb[kkk]):\n",
    "#     print('%3d' % i, np.linalg.norm(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('to_check.npy', {'c_emb': c_emb[kkk], 'c_ck': c_ck[kkk], 'q_ck': q_ck[kkk], 'att_ck': att_ck[kkk], 'match_ck': match_ck[kkk]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_len[kkk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_mask[kkk][159:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
