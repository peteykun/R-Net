{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from util import convert_tokens, get_batch_dataset, get_dataset, get_record_parser\n",
    "import tensorflow as tf\n",
    "from config import flags\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_string('f', 'give up already', 'who cares lol')\n",
    "config = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_file = 'data/retraining_dev_meta.json'\n",
    "test_record_file = 'data/retraining_dev.tf'\n",
    "\n",
    "with open(test_eval_file, \"r\") as fh:\n",
    "    eval_file = json.load(fh)\n",
    "\n",
    "meta = {'total': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.word_emb_file, \"r\") as fh:\n",
    "    word_mat = np.array(json.load(fh), dtype=np.float32)\n",
    "with open(config.char_emb_file, \"r\") as fh:\n",
    "    char_mat = np.array(json.load(fh), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_record_parser(config)\n",
    "train_dataset = get_batch_dataset('data/retraining_train.tf', parser, config)\n",
    "dev_dataset = get_dataset('data/retraining_dev.tf', parser, config)\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "dev_iterator = dev_dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(config, iterator, word_mat, char_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=sess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(var_list=[v for v in tf.global_variables() if not v.name.startswith('encoding_1/') and not v.name.startswith('badptr') and '/Adam' not in v.name and 'beta' not in v.name])\n",
    "print('Restoring', tf.train.latest_checkpoint(config.save_dir))\n",
    "saver.restore(sess, tf.train.latest_checkpoint(config.save_dir))\n",
    "sess.run(tf.assign(model.is_train, tf.constant(True, dtype=tf.bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "saver2 = tf.train.Saver()\n",
    "train_handle = sess.run(train_iterator.string_handle())\n",
    "dev_handle = sess.run(dev_iterator.string_handle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1, 5001):\n",
    "    loss, train_op = sess.run([model.loss, model.train_op], feed_dict={\n",
    "                              handle: train_handle})\n",
    "    \n",
    "    if _ % 10 == 0:\n",
    "        print('After', _, 'iterations:')\n",
    "        print('Batch Loss:', np.mean(loss))\n",
    "    \n",
    "    if _ % 100 == 0:\n",
    "        acc = 0\n",
    "\n",
    "        for __ in range(18):\n",
    "            pred1, target1, pred2, target2 = sess.run([tf.argmax(model.y1, 1), model.yp1,\n",
    "                                                       tf.argmax(model.y2, 1), model.yp2], feed_dict={handle: dev_handle})\n",
    "            acc += np.mean(np.logical_and(pred1 == target1, pred2 == target2))\n",
    "\n",
    "        acc /= float(18)\n",
    "        print('Dev Accuracy:', acc)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            saver2.save(sess, 'log/retraining_model/badptr-savepoint', global_step=_)\n",
    "    \n",
    "    if _ % 10 == 0:\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
